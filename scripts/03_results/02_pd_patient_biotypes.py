# -*- coding: utf-8 -*-
"""
This script generates results and figures used to investigate the PD patient
clustering solution generated by SNF
"""

import os.path as op
import warnings

from matplotlib import gridspec
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import scipy.stats as sstats
from sklearn.cluster import spectral_clustering
from sklearn import metrics
import statsmodels.formula.api as smf

from ppmi_snf import defaults, directories, structures, utils
from netneurotools import cluster, modularity, plotting

from analysis import (get_zrand_mask, load_longitudinal_behavior,
                      run_pdatrophy_anova, run_univariate_anova)

# set seaborn, numpy, matplotlib, warnings options
sns.set(style='white', context='notebook', font_scale=1.5)
warnings.filterwarnings('ignore', category=PendingDeprecationWarning)
warnings.filterwarnings('ignore', category=DeprecationWarning,
                        message='Calling np.sum')
plt.rcParams['svg.fonttype'] = 'none'
fontd = dict(size=36)

# miscellaneous settings
SAVE_FIGS = True  # whether to save figures
SEED = 1234  # random seed for reproducibility
np.random.seed(SEED)  # set random seed


def get_consensus_clusters(labels, zrand, verbose=True, seed=None):
    """
    Generates consensus cluster assignments from `labels` and `zrand`

    Parameters
    ----------
    labels : (K, M, C, N) array_like
        Cluster labels of `N` patients across SNF parameter space
    zrand : (C, K, M) array_like
        Local similarity of clustering solutions in SNF parameter space
    verbose : bool, optional
        Whether to print info about number of subjects in generated consensus
        clusters. Default: True
    seed : {None, int, np.random.RandomState}, optional
        Random seed for permutations. If not provided will use `SEED` specified
        at top of script. Default: None

    Returns
    -------
    assignments : (N, A) numpy.ndarray
        Cluster labels of `N` patients across `A` "stable" assignments
    consensus : (N,) numpy.ndarray
        Consensus clustering assignments for `N` patients
    agreement : (N, N) numpy.ndarray
        Agreement matrix containing probability of two patients being assigned
        to the same cluster across all `A` assignments
    """

    rs = np.random.RandomState(SEED if seed is None else seed)

    # only keep community assignments from stable regions
    mask = get_zrand_mask(zrand)
    assignments = labels[mask].reshape(-1, labels.shape[-1]).T

    # generate consensus assignments
    consensus, agreement = cluster.find_consensus(assignments,
                                                  null_func=np.mean,
                                                  return_agreement=True,
                                                  seed=rs)

    if verbose:
        grps, nums = np.unique(consensus, return_counts=True)
        print(f'Consensus clustering found {len(grps)} clusters: {nums}')

    return assignments, consensus, agreement


def run_modularity_test(agreement, consensus, n_perm=10000, seed=None):
    """
    Calculates modularity of `agreement` according to `consensus` clusters

    Parameters
    ----------
    agreement : (N, N) array_like
        Agreement matrix from which to calculate modularity
    consensus : (N,) array_like
        Cluster assignments for nodes in `agreement`
    n_perm : int, optional
        Number of permutations to use to assess significance of modularity.
        Default: 10000
    seed : {None, int, np.random.RandomState}, optional
        Random seed for permutations. If not provided will use `SEED` specified
        at top of script. Default: None

    Returns
    -------
    mod : float
        Modularity of `agreement` according to `consensus` clusters
    pval : float
        Non-parametric p-value of `mod`
    """

    rs = np.random.RandomState(SEED if seed is None else seed)

    # get baseline modularity to compare permutations to
    mod = modularity.get_modularity(agreement, consensus).sum()

    pval = 1  # numerator for p-value calculation
    for n in range(n_perm):
        # permute community labels and re-calculate modularity
        cons_perm = rs.permutation(consensus)
        mod_perm = modularity.get_modularity(agreement, cons_perm).sum()
        pval += (np.abs(mod_perm) > np.abs(mod))
    pval /= (n_perm + 1)  # calculate non-parametric p-value

    print(f'Modularity for agreement matrix: {mod:.3f}, p = {pval:.3f}')

    return mod, pval


def _chi2_test(data, variable):
    """
    Runs chi-squared test

    Parameters
    ----------
    data : pandas.DataFrame
        DataFrame with at least columns 'cluster', 'diagnosis', and `variable`
    variable : str
        Column in `data` on which to run chi-squared test

    Returns
    -------
    chi2 : float
        Chi-squared statistic from test
    pval : float
        P-value associated with `chi2`
    """

    data = data.groupby(['cluster', variable]).count()
    data = pd.pivot_table(data.dropna(axis=0, how='all').reset_index(),
                          index=variable, columns='cluster',
                          values='diagnosis').fillna(0)

    chi2, pval, *rest = sstats.chi2_contingency(np.asarray(data))

    return chi2, pval


def _foneway_test(data, variable):
    """
    Runs one-way ANOVA

    Parameters
    ----------
    data : pandas.DataFrame
        DataFrame with at least columns 'cluster' and `variable`
    variable : str
        Column in `data` on which to run ANOVA

    Returns
    -------
    F : float
        F-statistic from test
    pval : float
        P-value associated with `F`
    """

    data = data.groupby('cluster')
    data = [np.asarray(data.get_group(f)[variable]) for f in data.groups]

    F, pval = sstats.f_oneway(*data)

    return F, pval


def _run_cluster_test(data, confound, statistic):
    """
    Runs `statistic` test to examine group differences of `confound` in `data`

    Parameters
    ----------
    data : pandas.DataFrame
        DataFrame with at least columns 'cluster', 'diagnosis', and `variable`
    confound : str
        Column in `data` on which to run test
    statistic : {'F', 'chi2'}
        Which statistic should be used to assess cluster differences of
        `confound`

    Returns
    -------
    stat : float
        Test statistic
    pval : float
        P-value associated with `stat
    """

    tests = {
        'F': _foneway_test,
        'chi2': _chi2_test
    }

    # get appropriate test for desired statistic and run test
    stat, pval = tests.get(statistic)(data, confound)

    # for visualization / print purposes
    if statistic == 'chi2':
        statistic = '\N{GREEK SMALL LETTER CHI}\N{SUPERSCRIPT TWO}'

    # print output of test
    print('{:<10} {:<2} = {:>5.2f}, p = {:.2f}'
          .format(confound + ':', statistic, stat, pval))

    return stat, pval


def run_confound_tests(demographics):
    """
    Runs all confound tests for between-cluster differences in `demographics`

    Tests cluster differences for: gender, age, education, symptom duration,
    study site, and scanner strength

    Parameters
    ----------
    demographics : pandas.DataFrame
        DataFrame with demographic confound measures to test for cluster
        differences

    Returns
    -------
    confounds : dict
        Where keys are confounding variables and corresponding values are the
        relevant test statistic and associated p-value
    """

    # load scanner strength information and append to data frame
    tesla = pd.read_csv(op.join(directories.bids, 'tesla.csv'))
    data = pd.merge(demographics, tesla, on='participant')

    # calculate symptom duration
    sympdur = np.asarray((data['date_enroll'] - data['date_diagnosis'])
                         / np.timedelta64(1, 'Y'))
    data = data.assign(duration=sympdur)

    confounds = dict(
        gender='chi2',
        age='F',
        education='F',
        duration='F',
        site='chi2',
        tesla='chi2'
    )

    for variable, statistic in confounds.items():
        confounds[variable] = _run_cluster_test(data, variable, statistic)

    return confounds


def clean_visits(data, test, n_visits=100):
    """
    Drops rows of `data` with too few entries for given `test`

    Parameters
    ----------
    data : pandas.DataFrame
        Must have at least columns 'visit' and `test`
    test : str
        Column of `data` used to determine which rows to drop
    n_visits : int, optional
        Minimum number of participants with data for `test` at a given visit
        required to retain that visit

    Returns
    -------
    data : pandas.DataFrame
        Cleaned input `data`
    """

    if test not in data.columns:
        raise ValueError('Provide test "{}" not in data'.format(test))

    # determine which vists have sufficient datapoints
    data = data.dropna(subset=[test])
    visits = data.groupby('visit').count()
    visits = list(visits[visits['participant'] > n_visits].index)

    # drop "bad" visits and remove those as categories; also, convert the
    # visits column to a numerical value
    data = data.query(f'visit in {visits}')
    visit_codes = data['visit'].cat.remove_unused_categories().cat.codes
    data = data.assign(visit=visit_codes)

    return data


def run_lme(demographics, test):
    """
    Runs linear mixed effects model for `behavior` against `demographics`

    Parameters
    ----------
    demographics : pandas.DataFrame
        DataFrame containing demographic information on patients to be used
        as confounding variables in a longitudinal, linear mixed effects model
        of `test`
    test : str
        Which behavior should be set as the dependent variable in LME

    Returns
    -------
    model
        Generated LME model from `statsmodels`
    """

    cols = ['cluster', 'age', 'education', 'gender']
    missing = np.setdiff1d(cols, demographics.columns)
    if len(missing) > 0:
        raise ValueError('Provided `demographcis` missing required columns: '
                         '{}'.format(missing))

    # get longitudinal behavior for provided participants
    participants = list(demographics.index)
    behavior = load_longitudinal_behavior(participants)
    behavior = clean_visits(behavior, test)
    data = pd.merge(behavior, demographics, on='participant') \
             .dropna(subset=[test])

    # run linear mixed effects model and print summary
    model = smf.mixedlm(f'{test} ~ time * cluster + age + education + gender',
                        groups='participant', data=data).fit()
    print(model.summary())

    return model


def gen_figure(data, demographics, agreement, consensus, assignments, zrand):
    """
    Generates figure 3

    Parameters
    ----------
    data : list of pandas.DataFrame
    demographics : pandas.DataFrame
    agreement : (N, N) array_like
    consensus : (N,) array_like
    zrand : (C, K, M) array_like

    Returns
    -------
    fig : matplotlib.figure.Figure
        Plotted figure
    """

    # make figure
    fig = plt.figure(figsize=(16.5, 15))
    gs = gridspec.GridSpec(3, 15, figure=fig)
    gs.update(wspace=1.2, hspace=0.5)

    ax1, ax2, ax3 = (plt.subplot(gs[0, n:(n + 5)]) for n in [0, 5, 10])

    ###########################################################################
    # make hyperparameter similarity plot

    coll = ax1.imshow(zrand[1], cmap=defaults.similarity_cmap, alpha=0.7,
                      aspect='auto', vmin=50, vmax=150, rasterized=True)

    # make axis a bit prettier
    ax1.set(xticks=[], yticks=[], xticklabels=[], yticklabels=[])
    ax1.set_title('parameter stability', pad=20, fontsize=20)
    ax1.set_xlabel('scaling, Î¼', labelpad=7)
    ax1.set_ylabel('neighbors, K', labelpad=7)
    sns.despine(ax=ax1, left=True, bottom=True)

    # add colorbar to axis 1
    ax1_cbar = fig.colorbar(coll, ax=ax1, drawedges=False, ticks=[])
    ax1_cbar.outline.set(linewidth=0)
    ax1_cbar.ax.set_ylabel('local similarity', rotation=270, labelpad=25)
    ax1_cbar.ax.tick_params(axis='both', which='both', length=0)

    ###########################################################################
    # make cluster assignment map

    cbar_kws = {
        'ticks': [],
        'boundaries': np.arange(-0.5, 4.5)
    }
    # re-order community assignments for plotting purposes
    comms_plot, idxs = cluster.reorder_assignments(assignments, consensus,
                                                   seed=SEED)
    ax2 = sns.heatmap(comms_plot, cmap=defaults.four_cluster_cmap,
                      xticklabels=[], yticklabels=[],
                      ax=ax2, cbar_kws=cbar_kws, rasterized=True)
    hlines = np.where(np.diff(consensus[consensus.argsort()]))[0] + 1
    ax2.hlines(hlines, 0, comms_plot.shape[-1], color='white', linewidth=2)
    ax2.set_title('patient clusters', pad=20, fontsize=20)
    ax2.set_xlabel('cluster partitions', labelpad=7)
    ax2.set_ylabel('patients', labelpad=7)

    # modify colorbar
    cbar = ax2.collections[0].colorbar
    cbar.outline.set(linewidth=0)
    cbar.ax.set_ylabel('cluster label', rotation=270, labelpad=25)
    cbar.ax.tick_params(axis='both', which='both', length=0)

    ###########################################################################
    # make sorted cluster heatmap

    ax3 = plotting.plot_mod_heatmap(agreement, consensus, ax=ax3,
                                    inds=idxs[0].squeeze(), rasterized=True,
                                    cmap='viridis', edgecolor='white')
    ax3.set(xticks=[], yticks=[], xticklabels=[], yticklabels=[])
    ax3.set_title('patient co-assignment', pad=20, fontsize=20)
    ax3.set_xlabel('patients', labelpad=7)
    ax3.set_ylabel('patients', labelpad=7)

    # modify colorbar
    cbar = ax3.collections[0].colorbar
    cbar.set_ticks([])
    cbar.outline.set(linewidth=0)
    cbar.ax.set_ylabel('probability', rotation=270, labelpad=25)
    cbar.ax.tick_params(axis='both', which='both', length=0)

    # add figure labels
    for ax, text in zip([ax1, ax2, ax3], ['a', 'b', 'c']):
        ax.text(-0.2, 1.1, text, transform=ax.transAxes, fontdict=fontd)

    ###########################################################################
    # make rainplots

    axes = [plt.subplot(gs[1, r:(r + 3)]) for r in range(0, 15, 3)]
    titles = [
        'cortical thickness',
        'subcortical volume',
        'dopamine binding',
        'protein availability',
        'clinical score'
    ]
    xlabels = {
        'supramarginal_15_r': 'supramarginal gyrus',
        'substantia_nigra_pars_compacta': 'substantia nigra',
        'caudate_l': 'left caudate',
        'ttau': 'total tau',
        'tremor': 'tremor'
    }
    for dat, ax, title in zip(data, axes, titles):
        # z-score data for plotting
        zdat = sstats.zscore(dat, ddof=1)
        zdf = pd.DataFrame(zdat, index=dat.index, columns=dat.columns)
        currdata = pd.merge(demographics[['cluster']], zdf, on='participant')

        # find maximally discriminating feature in data
        grps = (zdat[consensus == cl] for cl in np.unique(consensus))
        idx = sstats.f_oneway(*grps).statistic.argmax()
        xlabel = xlabels.get(zdf.columns[idx])

        # make rainplot
        utils.rainplot(x=dat.columns[idx], y='cluster', data=currdata,
                       viol_kws={'linewidth': 0}, ax=ax,
                       palette=defaults.three_cluster_cmap)

        # make axis goodness
        ax.set(xticklabels=[-2.5, 2.5], yticklabels=[], ylabel='',
               xlabel=title, xlim=(-3.5, 3.5), xticks=[-2.5, 2.5])
        ax.set_title(xlabel, pad=15)
        sns.despine(ax=ax, left=True)
        utils.shift_axis(ax, lshift=0, rshift=0.02)

    axes[0].text(-0.3, 1.10, 'd', transform=axes[0].transAxes, fontdict=fontd)

    ###########################################################################
    # make lineplot

    behavior = load_longitudinal_behavior(demographics.index)
    axes_lp = [plt.subplot(gs[2, r:(r + 4)]) for r in [4, 9]]
    for n, (lp, ax) in enumerate(zip(['pigd', 'tremor'], axes_lp)):
        # get data for given test
        pd_test = pd.merge(clean_visits(behavior, lp), demographics,
                           on='participant')
        # normalize data based on first visit mean/stdev
        t = pd_test.query('visit == 0')[lp]
        pd_test.loc[:, lp] -= t.mean()
        pd_test.loc[:, lp] /= t.std(ddof=1)
        # plot it
        sns.lineplot(x='visit', y=lp, data=pd_test.dropna(subset=[lp]),
                     hue='cluster', palette=defaults.three_cluster_cmap,
                     legend=False, ci=68, ax=ax)
        ax.set(xticklabels=[], xlabel='time')
        if n == 0:
            ax.set_ylabel('clinical severity', labelpad=10)
            ax.text(-0.3, 1.10, 'e', transform=ax.transAxes, fontdict=fontd)
            ax.set(ylim=[-0.5, 2.5], yticks=[-0.5, 0.5, 1.5, 2.5],
                   yticklabels=[-0.5, 0.5, 1.5, 2.5])
        else:
            ax.set(ylim=[-0.75, 0.75], ylabel='',
                   yticks=[-0.75, 0, 0.75],
                   yticklabels=[-0.75, 0, 0.75])
        ax.set_title(lp, pad=15)
        sns.despine(ax=ax)

    ###########################################################################
    # shift axes to make room for everything

    utils.shift_axis(ax1, lshift=0.04)
    utils.shift_axis(ax1_cbar.ax, lshift=0.04)
    utils.shift_axis(ax2, lshift=0.06)
    utils.shift_axis(ax2.collections[0].colorbar.ax, lshift=0.06)
    utils.shift_axis(ax3, lshift=0.08)
    utils.shift_axis(ax3.collections[0].colorbar.ax, lshift=0.08)

    for a, lshift in zip(axes[1:], np.cumsum([0.02] * 4)):
        utils.shift_axis(a, lshift=lshift)

    utils.shift_axis(axes_lp[0], lshift=-0.05, rshift=0.01, tshift=-0.018)
    utils.shift_axis(axes_lp[1], rshift=0.05, lshift=-0.01, tshift=-0.018)

    return fig


def supplementary_longitudinal_outcomes(demographics):
    """ For supplementary longitudinal outcome figures """

    behavior = load_longitudinal_behavior(demographics.index)
    fig, axes = plt.subplots(1, 2, figsize=(9, 4))
    fig.subplots_adjust(wspace=0.3)

    for n, (lp, ax) in enumerate(zip(['pigd', 'tremor'], axes)):
        # get data for given test
        pd_test = pd.merge(clean_visits(behavior, lp), demographics,
                           on='participant')
        # normalize data based on first visit mean/stdev
        t = pd_test.query('visit == 0')[lp]
        pd_test.loc[:, lp] -= t.mean()
        pd_test.loc[:, lp] /= t.std(ddof=1)
        # plot it
        sns.lineplot(x='visit', y=lp, data=pd_test.dropna(subset=[lp]),
                     hue='cluster', palette=defaults.three_cluster_cmap,
                     legend=False, ci=68, ax=ax)
        ax.set(xticklabels=[], xlabel='time')
        if n == 0:
            ax.set_ylabel('clinical severity', labelpad=10)
            ax.set(yticks=[-0.5, 0.5, 1.5, 2.5],
                   yticklabels=[-0.5, 0.5, 1.5, 2.5])
        else:
            ax.set(ylabel='',
                   yticks=[-0.75, 0, 0.75],
                   yticklabels=[-0.75, 0, 0.75])
        ax.set_title(lp, pad=15)
        sns.despine(ax=ax)

    return fig


def main():
    keys = [
        'cortical_thickness',
        'subcortical_volume',
        'dat_scans',
        'csf_assays',
        'behavioral_measures'
    ]

    # load processed data
    fname = op.join(directories.snf, f'scale500_deterministic.h5')
    hdf = structures.Frog(fname)
    data = [hdf.load(f'/processed/pd_{key}') for key in keys]

    # load demographics information
    demographics = hdf.load('/raw/pd_demographics')
    demographics['gender'] = demographics['gender'].cat.remove_unused_categories()

    # also load the gridsearch results back in to memory.
    # here, labels is shape (K, M, C, N), and
    #        zrand is shape (C, K, M)
    # where `K` is the nearest-neighbors parameter of SNF
    #       `M` is the scaling (mu) parameter of SNF, and
    #       `C` is the different cluster # solutions (2, 3, & 4 clusters), and
    #       `N` is PD patients
    labels = hdf.load('/snf/processed/all/sqeuclidean/gridsearch/labels')
    zrand = hdf.load('/snf/processed/all/sqeuclidean/gridsearch/zrand')

    # find consensus clusters and update demographics table
    print('=' * 80)
    print('Generating consensus clustering assignments\n')
    assignments, consensus, agreement = get_consensus_clusters(labels, zrand)
    demographics = demographics.assign(cluster=pd.Categorical(consensus))

    # run all the different tests assessing the clusters
    print('\n' + '=' * 80)
    print('Testing modularity of agreement matrix for consensus clusters\n')
    run_modularity_test(agreement, consensus)

    print('\n' + '=' * 80)
    print('Testing cluster differences for confounding variables\n')
    run_confound_tests(demographics)

    print('\n' + '=' * 80)
    print('Running mass-univariate ANOVA for cluster differences\n')
    run_univariate_anova(data, demographics, run_tukey=False)

    print('\n' + '=' * 80)
    print('Testing cluster differences in PD-ICA atrophy score\n')
    run_pdatrophy_anova(demographics.reset_index())

    print('\n' + '=' * 80)
    print('Running longitudinal models for PIGD + tremor scores\n')
    run_lme(demographics, 'pigd')
    run_lme(demographics, 'tremor')

    # use all this info to generate what will serve as the basis for figure 4
    fig = gen_figure(data, demographics, agreement, consensus, assignments,
                     zrand)
    if SAVE_FIGS:
        fname = op.join(directories.figs, 'patient_clusters')
        utils.savefig(fname, fig)

    # figures for comparing longitudinal outcomes from SNF-derived biotypes
    # with biotypes derived from other subsets of data / methodologies
    # first, start with biotypes produced from all data w/SNF
    path = '/snf/processed/{}/sqeuclidean/gridsearch/consensus'
    clusters = [
        hdf[path.format('all')],
        hdf[path.format('behavioral_measures')],
        spectral_clustering(
            metrics.pairwise.cosine_similarity(
                sstats.zscore(np.column_stack(data), ddof=1)
            ) + 1,
            n_clusters=3, random_state=1234
        )
    ]
    for clust, fn in zip(clusters, ['snf', 'behavior', 'concatenate']):
        demographics = demographics.assign(cluster=pd.Categorical(clust))
        fig = supplementary_longitudinal_outcomes(demographics)
        run_lme(demographics, 'pigd')
        run_lme(demographics, 'tremor')
        if SAVE_FIGS:
            utils.savefig(op.join(directories.figs, 'supp_long', fn), fig)
            plt.close(fig=fig)


if __name__ == "__main__":
    main()
